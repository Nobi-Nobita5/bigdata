1. ODS层数据采集直接从日志系统发送到kafka，没有用flume采集文件
2. 消费者将数据分流使用Dstream API，没有使用spark structured streaming。

3. 问题，偏移量Offset自动提交不能实现消费者【精确一次消费】的两种解决办法：

   1）将消费者【写出数据】和【提交offset】的动作，用关系型数据库的事务进行处理

   2）在【写出数据】之后，在Driver端手动提交偏移量，【一个数据批次foreachRDD】提交一次，保证数据不会丢失。

   ​      幂等性处理，保证数据不重复消费。（看使用的数据库，一般般有主键的数据库都支持幂等性操作 upsert）。

   ​      注：项目中此处kafka 中的数据只是用于中间存储,并不会进行统计，所以只要保证不丢失即可，重复数据的幂等性处理可以交给下游处理。

4. 问题，生产者会先将消息发送到缓冲区中，如果缓冲区的数据还没有刷写到Broker，此时kafka集群故障，且offset已提交，此部分的数据就会丢失。解决办法：

   1）将消息改为同步发送，foreach()中每缓存一条数据就flush()发送到【kafka集群(磁盘)】中。会牺牲性能。

   2）在手动提交 offset 之前，强制将缓冲区的数据 flush 到 broker：

   ​	  使用rdd.foreachPartition()算子替换掉foreach()算子。foreach()算子里面的代码会在【每个executor端】执行，rdd.foreachPartition()算子里的代码也是在【每个executor端】执行，但是只会【每批次每分区执行一次】。详见com.atguigu.gmall.realtime.app.OdsBaseLogApp.scala代码。

   注：项目中此处的生产者是指代码的中间生产者，负责将ODS层的中间消费者处理的数据发送到DWD。

